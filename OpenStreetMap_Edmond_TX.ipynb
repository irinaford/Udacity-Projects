{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OpenStreetMap Project**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries:\n",
    "\n",
    "import xml.etree.cElementTree as ET\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import csv\n",
    "import codecs\n",
    "import cerberus\n",
    "import schema\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to create smaller osm file by taking every 20th element in original file:\n",
    "\n",
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\n",
    "OSM_FILE = \"Edmond.osm\"  # Replace this with your osm file\n",
    "SAMPLE_FILE = \"Edmond_sample.osm\"\n",
    "\n",
    "k = 20 # Parameter: take every k-th top level element\n",
    "\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    \"\"\"Yield element if it is the right type of tag\n",
    "\n",
    "    Reference:\n",
    "    http://stackoverflow.com/questions/3095434/inserting-newlines-in-xml-file-generated-via-xml-etree-elementtree-in-python\n",
    "    \"\"\"\n",
    "    context = iter(ET.iterparse(osm_file, events=('start', 'end')))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()\n",
    "\n",
    "            \n",
    "with open(SAMPLE_FILE, 'wb') as output:\n",
    "    output.write('<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n')\n",
    "    output.write('<osm>\\n  ')\n",
    "\n",
    "    # Write every kth top level element\n",
    "    for i, element in enumerate(get_element(OSM_FILE)):\n",
    "        if i % k == 0:\n",
    "            output.write(ET.tostring(element, encoding='utf-8'))\n",
    "\n",
    "    output.write('</osm>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bounds': 1,\n",
      " 'member': 14233,\n",
      " 'meta': 1,\n",
      " 'nd': 769842,\n",
      " 'node': 696135,\n",
      " 'note': 1,\n",
      " 'osm': 1,\n",
      " 'relation': 655,\n",
      " 'tag': 324255,\n",
      " 'way': 58104}\n"
     ]
    }
   ],
   "source": [
    "# Count tags in osm file:\n",
    "\n",
    "def count_tags(filename):\n",
    "    tags_dict = {}\n",
    "    for event, elem in ET.iterparse(filename):\n",
    "        try:\n",
    "            if elem.tag in tags_dict:\n",
    "                tags_dict[elem.tag] += 1\n",
    "            else:\n",
    "                tags_dict[elem.tag] = 1\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    return tags_dict\n",
    "    \n",
    "tags = count_tags('Edmond.osm')\n",
    "pprint.pprint(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify original osm file by creating new tags 'addr:street' and 'addr:postcode' in the 'tiger'-type elements\n",
    "# where the street name is contained as the value in the tag with the key = 'name', and postcode as the value\n",
    "# in the tag with the key = 'tiger:zip_left'\n",
    "# New file is called 'Edmond.xml'\n",
    "\n",
    "# REFERENCE: https://stackoverflow.com/questions/50998718/take-2-xml-elements-and-merge-into-1-new-element-python\n",
    "\n",
    "osmfile = 'Edmond.osm'\n",
    "tree = ET.parse(osmfile)\n",
    "\n",
    "expected = [\"Avenue\", \"Boulevard\", \"Circle\", \"Commons\", \"Court\", \"Drive\", \"Lane\", \"Parkway\", \"Place\", \"Road\", \"Square\", \"Street\", \n",
    "            \"Trail\", \"Terrace\", \"Turnpike\", \"Way\"]\n",
    "\n",
    "doc = tree.getroot()\n",
    "for way in doc.findall(\".//way\"):\n",
    "    wname = way.find('.//tag[@k=\"name\"]')\n",
    "    if wname != None:\n",
    "        newName = wname.attrib[\"v\"]\n",
    "        for e in expected:\n",
    "            if e in newName:\n",
    "                if way.find('.//tag[@k=\"addr:street\"]') is None:\n",
    "                    newNode = ET.SubElement(way, 'tag k=\"addr:street\" v=\"{}\"'.format(newName))\n",
    "        wpcode = way.find('.//tag[@k=\"tiger:zip_left\"]')\n",
    "        \n",
    "        if wpcode != None:\n",
    "            newPcode = wpcode.attrib[\"v\"]\n",
    "        \n",
    "            if way.find('.//tag[@k=\"addr:postcode\"]') is None:\n",
    "                newNode = ET.SubElement(way, 'tag k=\"addr:postcode\" v=\"{}\"'.format(newPcode))\n",
    "            \n",
    "for node in doc.findall(\".//node\"):\n",
    "    nname = node.find('.//tag[@k=\"name\"]')\n",
    "    if nname != None:\n",
    "        newName = nname.attrib[\"v\"]\n",
    "        for e in expected:\n",
    "            if e in newName:\n",
    "                if node.find('.//tag[@k=\"addr:street\"]') is None:\n",
    "                    newNode = ET.SubElement(node, 'tag k=\"addr:street\" v=\"{}\"'.format(newName))\n",
    "        npcode = node.find('.//tag[@k=\"tiger:zip_left\"]')\n",
    "        if npcode != None:\n",
    "            newPcode = npcode.attrib[\"v\"]\n",
    "            if node.find('.//tag[@k=\"addr:postcode\"]') is None:\n",
    "                newNode = ET.SubElement(node, 'tag k=\"addr:postcode\" v=\"{}\"'.format(newPcode))\n",
    "\n",
    "tree.write(r\"Edmond.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lower': 157235, 'lower_colon': 122886, 'other': 65185, 'problemchars': 0}\n"
     ]
    }
   ],
   "source": [
    "# Code to find and count key types for elements in the file:\n",
    "\n",
    "lower = re.compile(r'^([a-z]|_)*$')\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "def key_type(element, keys):\n",
    "    if element.tag == \"tag\":\n",
    "\n",
    "        if lower.search(element.attrib[\"k\"]):\n",
    "            keys[\"lower\"] += 1\n",
    "             \n",
    "        elif lower_colon.search(element.attrib[\"k\"]):\n",
    "            keys[\"lower_colon\"] += 1\n",
    "            \n",
    "        elif problemchars.search(element.attrib[\"k\"]):\n",
    "            keys[\"problemchars\"] += 1\n",
    "            \n",
    "        else:\n",
    "            keys[\"other\"] += 1\n",
    "            \n",
    "    return keys\n",
    "            \n",
    "\n",
    "def process_map(filename):\n",
    "    keys = {\"lower\": 0, \"lower_colon\": 0, \"problemchars\": 0, \"other\": 0}\n",
    "    for _, element in ET.iterparse(filename):\n",
    "        keys = key_type(element, keys)\n",
    "\n",
    "    return keys\n",
    "\n",
    "keys = process_map('Edmond.xml')\n",
    "pprint.pprint(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "515\n"
     ]
    }
   ],
   "source": [
    "# Code to count all users contributing to creation of the file:\n",
    "\n",
    "def get_user(element):\n",
    "    return\n",
    "\n",
    "def process_map(filename):\n",
    "    users = set()\n",
    "    for _, element in ET.iterparse(filename):\n",
    "        user = 'uid'\n",
    "        if user in element.attrib:\n",
    "            users.add(element.attrib[user])\n",
    "    return users\n",
    "\n",
    "users = process_map('Edmond.xml')\n",
    "print len(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Circle Glen => Circle Glen\n",
      "Memorial Road Church of Christ => Memorial Road Church of Christ\n",
      "BLUE JAY DRIVE => BLUE JAY DRIVE\n",
      "West Danforth => West Danforth\n",
      "W Britton Rd => West Britton Road\n",
      "W. Covell Rd => W. Covell Road\n",
      "W I-35 Frontage Rd => West I-35 Frontage Road\n",
      "W Covell Rd => West Covell Road\n",
      "West Memorial Rd => West Memorial Road\n",
      "W Danforth Rd => West Danforth Road\n",
      "West I 35 Frontage Rd => West I 35 Frontage Road\n",
      "W Memorial Rd => West Memorial Road\n",
      "Highland Trails Baseball Field => Highland Trails Baseball Field\n",
      "NW `155TH STREET => Northwest `155TH Street\n",
      "NW 156TH STREET => Northwest 156TH Street\n",
      "NW 164TH STREET => Northwest 164TH Street\n",
      "NW 155TH STREET => Northwest 155TH Street\n",
      "NW 150TH STREET => Northwest 150TH Street\n",
      "Highland Trails Playground => Highland Trails Playground\n",
      "East Highway 66 => East Highway 66\n",
      "Highway 66 => Highway 66\n",
      "West Lake Hefner Dr. => West Lake Hefner Dr.\n",
      "Road Not Taken => Road Not Taken\n",
      "Northwest Expressway => Northwest Expressway\n",
      "Hilltop Drive (S3296 Rd) => Hilltop Drive (S3296 Rd)\n",
      "Sonny Blues Pl => Sonny Blues Place\n",
      "SOnny Blues Pl => SOnny Blues Place\n",
      "Bert Cooper Trails (Lake Hefner Trails) => Bert Cooper Trails (Lake Hefner Trails)\n",
      "Heritage Lanes => Heritage Lanes\n",
      "N MacArthur => North MacArthur\n",
      "Trails South Park => Trails South Park\n",
      "Wayne Schooley Park => Wayne Schooley Park\n",
      "Town Square Park => Town Square Park\n",
      "Edmond Road NE => Edmond Road Northeast\n",
      "Chisholm Lane NE => Chisholm Lane Northeast\n",
      "North May Ave => North May Avenue\n",
      "E.R.A. Courtyard => E.R.A. Courtyard\n",
      "Tennis Courts => Tennis Courts\n",
      "NW 150th => Northwest 150th\n",
      "Babbling Brook Dr => Babbling Brook Dr\n",
      "Highland Trails Club House and Pool => Highland Trails Club House and Pool\n",
      "West I-35 Frontage => West I-35 Frontage\n",
      "Broadway Extension => Broadway Extension\n",
      "North Broadway Extension => North Broadway Extension\n",
      "W Hefner Rd STE F => West Hefner Road STE F\n",
      "Circle K => Circle K\n",
      "East 10th Street Plaza => East 10th Street Plaza\n",
      "E 19th St => East 19th Street\n",
      "2nd St => 2nd Street\n",
      "Bond St => Bond Street\n",
      "NW 157th St => Northwest 157th Street\n",
      "East 2nd St => East 2nd Street\n",
      "E 2nd St => East 2nd Street\n",
      "Lanes Turn => Lanes Turn\n",
      "NORTH MAY AVE => NORTH MAY AVE\n",
      "NORTH PENNSYLVANIA AVE => NORTH PENNSYLVANIA AVE\n",
      "Eastern Oklahoma County Turnpike => Eastern Oklahoma County Turnpike\n",
      "John Kilpatrick Turnpike => John Kilpatrick Turnpike\n",
      "Governor Roy Joseph Turner Turnpike => Governor Roy Joseph Turner Turnpike\n",
      "N Classen Blvd #103 => North Classen Blvd #103\n",
      "Thunder Road Raceway => Thunder Road Raceway\n",
      "Bell Tolls Terr => Bell Tolls Terrace\n",
      "N Lincoln => North Lincoln\n",
      "Woodhollow Trail Park and Frisbee Golf => Woodhollow Trail Park and Frisbee Golf\n",
      "Highland Trails Basketball Cout => Highland Trails Basketball Cout\n",
      "University Commons Apartments => University Commons Apartments\n",
      "Aspen Place Apartments => Aspen Place Apartments\n",
      "Council Place Apartments => Council Place Apartments\n",
      "Arrowhead Trails => Arrowhead Trails\n",
      "Bert Cooper Trails => Bert Cooper Trails\n",
      "North Interstate 35 => North Interstate 35\n",
      "Lawson Way Farms => Lawson Way Farms\n",
      "Thunder Roadhouse => Thunder Roadhouse\n",
      "Texas Roadhouse => Texas Roadhouse\n",
      "Chase Drive Through => Chase Drive Through\n",
      "Walgreens Drive Through => Walgreens Drive Through\n",
      "MidFirst Bank ATM Drive Through => MidFirst Bank ATM Drive Through\n",
      "City Bites Drive Through => City Bites Drive Through\n",
      "Hi-Way Church => Hi-Way Church\n",
      "Classen Boulevard Baptist Church => Classen Boulevard Baptist Church\n",
      "Waterloo Road Baptist Church => Waterloo Road Baptist Church\n",
      "Edmond Road Baptist Church => Edmond Road Baptist Church\n",
      "Highland Park Blvd => Highland Park Blvd\n",
      "William Penn Blvd => William Penn Blvd\n",
      "South Broadway => South Broadway\n",
      "WingStreet => WingStreet\n"
     ]
    }
   ],
   "source": [
    "# THIS IS THE MAIN CODE IN THE PROJECT\n",
    "# Combine codes audit.py and data.py from Udacity Case Study to audit and clean the data and write to csv files:\n",
    "\n",
    "# REFERENCE: https://libraries.io/github/mkuehn10/P3-Wrangle-OpenStreetMap-Data\n",
    "\n",
    "OSMFILE = \"Edmond.xml\"\n",
    "\n",
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "postcode_type_re = re.compile(r'.*(\\d{5}(\\-\\d{4})?)$')\n",
    "\n",
    "postcodes = set()                            \n",
    "\n",
    "expected = [\"Avenue\", \"Boulevard\", \"Circle\", \"Commons\", \"Court\", \"Drive\", \"Lane\", \"Parkway\", \"Place\", \"Road\", \"Square\", \"Street\", \n",
    "            \"Trail\", \"Terrace\", \"Way\", \"North\", \"Northwest\", \"Northeast\", \"South\", \"Southwest\", \"Southeast\", \"East\", \"West\"]\n",
    "\n",
    "\n",
    "mapping = { \"St\": \"Street\",\n",
    "            \"St.\": \"Street\",\n",
    "            \"STREET\": \"Street\",\n",
    "            \"Rd\": \"Road\",\n",
    "            \"Rd.\": \"Road\",\n",
    "            \"Ave\": \"Avenue\",\n",
    "            \"Pl\": \"Place\",\n",
    "            \"Terr\": \"Terrace\",\n",
    "            \"N\": \"North\",\n",
    "            \"NW\": \"Northwest\",\n",
    "            \"NE\": \"Northeast\",\n",
    "            \"S\": \"South\",\n",
    "            \"SW\": \"Southwest\",\n",
    "            \"SE\": \"Southeast\",\n",
    "            \"E\": \"East\",\n",
    "            \"W\": \"West\"\n",
    "        }\n",
    "\n",
    "\n",
    "def audit_street_type(street_types, street_name):\n",
    "    \n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type not in expected:\n",
    "            street_types[street_type].add(street_name)\n",
    "\n",
    "def is_street_name(elem):\n",
    "    return (elem.attrib['k'] == \"addr:street\")\n",
    "\n",
    "def is_postcode(elem):\n",
    "    return (elem.attrib['k'] == \"addr:postcode\")\n",
    "\n",
    "def audit(osmfile):\n",
    "    \n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    street_types = defaultdict(set)\n",
    "    postcode_types = defaultdict(set)\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_street_name(tag):\n",
    "                    audit_street_type(street_types, tag.attrib['v'])\n",
    "                elif is_postcode(tag):\n",
    "                    postcodes.add(tag.attrib['v'])\n",
    "                \n",
    "    osm_file.close()\n",
    "    return street_types\n",
    "\n",
    "\n",
    "def clean_street_name(name, mapping):\n",
    "    better_name = []\n",
    "    for split_name in name.split(' '):\n",
    "        if split_name in mapping.keys():\n",
    "            split_name = mapping[split_name]\n",
    "        better_name.append(split_name)\n",
    "    \n",
    "    better_name = ' '.join(better_name)\n",
    "    return better_name\n",
    "\n",
    "#st_types = audit(OSMFILE)\n",
    "#for st_type, ways in st_types.iteritems():\n",
    "#    for name in ways:\n",
    "#        better_name = clean_street_name(name, mapping)\n",
    "#        print name, \"=>\", better_name\n",
    "\n",
    "\n",
    "NODES_PATH = \"nodes.csv\"\n",
    "NODE_TAGS_PATH = \"nodes_tags.csv\"\n",
    "WAYS_PATH = \"ways.csv\"\n",
    "WAY_NODES_PATH = \"ways_nodes.csv\"\n",
    "WAY_TAGS_PATH = \"ways_tags.csv\"\n",
    "\n",
    "LOWER_COLON = re.compile(r'^([a-z]|_)+:([a-z]|_)+')\n",
    "PROBLEMCHARS = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "SCHEMA = schema.Schema\n",
    "\n",
    "# Make sure the fields order in the csvs matches the column order in the sql table schema\n",
    "NODE_FIELDS = ['id', 'lat', 'lon', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "NODE_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_FIELDS = ['id', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "WAY_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_NODES_FIELDS = ['id', 'node_id', 'position']\n",
    "\n",
    "def shape_element(element, node_attr_fields=NODE_FIELDS, way_attr_fields=WAY_FIELDS,\n",
    "                  problem_chars=PROBLEMCHARS, default_tag_type='regular'):\n",
    "    \"\"\"Clean and shape node or way XML element to Python dict\"\"\"\n",
    "\n",
    "    node_attribs = {}\n",
    "    way_attribs = {}\n",
    "    way_nodes = []\n",
    "    tags = []  # Handle secondary tags the same way for both node and way elements\n",
    "    if element.tag == 'node':\n",
    "        for attrib in NODE_FIELDS:\n",
    "            if attrib in element.attrib:\n",
    "                node_attribs[attrib] = element.attrib[attrib]\n",
    "            \n",
    "        for sec in element.iter(\"tag\"):\n",
    "            if sec.attrib[\"k\"] == \"addr:street\":\n",
    "                sec.attrib[\"v\"] = clean_street_name(sec.attrib[\"v\"], mapping) \n",
    "            if sec.attrib[\"k\"] == \"addr:postcode\":\n",
    "                sec.attrib[\"v\"] = sec.attrib[\"v\"][:5]\n",
    "            tag_dict = {'id': None, 'key': None, 'value': None, 'type': None}\n",
    "            tag_dict[\"id\"] = element.attrib[\"id\"]\n",
    "            tag_dict[\"value\"] = sec.attrib[\"v\"]\n",
    "            tag_dict[\"type\"] = default_tag_type\n",
    "            k_v = sec.attrib[\"k\"]\n",
    "\n",
    "            if ':' in k_v:\n",
    "                type, key = k_v.split(':', 1)\n",
    "                tag_dict[\"key\"] = key\n",
    "                tag_dict[\"type\"] = type\n",
    "            else:\n",
    "                tag_dict[\"key\"] = k_v\n",
    "            tags.append(tag_dict)\n",
    "        \n",
    "    \n",
    "    if element.tag == \"way\":\n",
    "        for attrib in WAY_FIELDS:\n",
    "            if attrib in element.attrib:\n",
    "                way_attribs[attrib] = element.attrib[attrib]\n",
    "                \n",
    "        for c, tag_dict in enumerate(element.iter(\"nd\")):\n",
    "            way_node = {\"id\": None, \"node_id\": None, \"position\": 0}\n",
    "            way_node[\"id\"] = element.attrib[\"id\"]\n",
    "            way_node[\"node_id\"] = tag_dict.attrib[\"ref\"]\n",
    "            way_node[\"position\"] = c\n",
    "            way_nodes.append(way_node)\n",
    "        \n",
    "        for sec in element.iter(\"tag\"):\n",
    "            if sec.attrib[\"k\"] == \"addr:street\":\n",
    "                sec.attrib[\"v\"] = clean_street_name(sec.attrib[\"v\"], mapping) \n",
    "            if sec.attrib[\"k\"] == \"addr:postcode\":\n",
    "                sec.attrib[\"v\"] = sec.attrib[\"v\"][:5] \n",
    "            \n",
    "            tag_dict = {'id': None, 'key': None, 'value': None, 'type': None}\n",
    "            tag_dict[\"id\"] = element.attrib[\"id\"]\n",
    "            tag_dict[\"value\"] = sec.attrib[\"v\"]\n",
    "            tag_dict[\"type\"] = default_tag_type\n",
    "            k_v = sec.attrib[\"k\"]\n",
    "            \n",
    "            if ':' in k_v:\n",
    "                type, key = k_v.split(':', 1)\n",
    "                tag_dict[\"key\"] = key\n",
    "                tag_dict[\"type\"] = type\n",
    "            else:\n",
    "                tag_dict[\"key\"] = k_v\n",
    "            tags.append(tag_dict)\n",
    "        \n",
    "    if element.tag == 'node':\n",
    "        return {'node': node_attribs, 'node_tags': tags}\n",
    "    elif element.tag == 'way':\n",
    "        return {'way': way_attribs, 'way_nodes': way_nodes, 'way_tags': tags}\n",
    "\n",
    "\n",
    "# ================================================== #\n",
    "#               Helper Functions                     #\n",
    "# ================================================== #\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    \"\"\"Yield element if it is the right type of tag\"\"\"\n",
    "\n",
    "    context = ET.iterparse(osm_file, events=('start', 'end'))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()\n",
    "\n",
    "\n",
    "# ERROR DURING VALIDATION\n",
    "            \n",
    "#def validate_element(element, validator, schema=SCHEMA):\n",
    "#    \"\"\"Raise ValidationError if element does not match schema\"\"\"\n",
    "#    if validator.validate(element, schema) is not True:\n",
    "#        field, errors = next(validator.errors.iteritems())\n",
    "#        message_string = \"\\nElement of type '{0}' has the following errors:\\n{1}\"\n",
    "#        error_string = pprint.pformat(errors)\n",
    "#        raise Exception(message_string.format(field, error_string))\n",
    "\n",
    "\n",
    "class UnicodeDictWriter(csv.DictWriter, object):\n",
    "    \"\"\"Extend csv.DictWriter to handle Unicode input\"\"\"\n",
    "\n",
    "    def writerow(self, row):\n",
    "        super(UnicodeDictWriter, self).writerow({\n",
    "            k: (v.encode('utf-8') if isinstance(v, unicode) else v) for k, v in row.iteritems()\n",
    "        })\n",
    "\n",
    "    def writerows(self, rows):\n",
    "        for row in rows:\n",
    "            self.writerow(row)\n",
    "\n",
    "\n",
    "# ================================================== #\n",
    "#               Main Function                        #\n",
    "# ================================================== #\n",
    "def process_map(file_in, validate):\n",
    "    \"\"\"Iteratively process each XML element and write to csv(s)\"\"\"\n",
    "\n",
    "    with codecs.open(NODES_PATH, 'w') as nodes_file, \\\n",
    "         codecs.open(NODE_TAGS_PATH, 'w') as nodes_tags_file, \\\n",
    "         codecs.open(WAYS_PATH, 'w') as ways_file, \\\n",
    "         codecs.open(WAY_NODES_PATH, 'w') as way_nodes_file, \\\n",
    "         codecs.open(WAY_TAGS_PATH, 'w') as way_tags_file:\n",
    "\n",
    "        nodes_writer = UnicodeDictWriter(nodes_file, NODE_FIELDS)\n",
    "        node_tags_writer = UnicodeDictWriter(nodes_tags_file, NODE_TAGS_FIELDS)\n",
    "        ways_writer = UnicodeDictWriter(ways_file, WAY_FIELDS)\n",
    "        way_nodes_writer = UnicodeDictWriter(way_nodes_file, WAY_NODES_FIELDS)\n",
    "        way_tags_writer = UnicodeDictWriter(way_tags_file, WAY_TAGS_FIELDS)\n",
    "\n",
    "        nodes_writer.writeheader()\n",
    "        node_tags_writer.writeheader()\n",
    "        ways_writer.writeheader()\n",
    "        way_nodes_writer.writeheader()\n",
    "        way_tags_writer.writeheader()\n",
    "\n",
    "        validator = cerberus.Validator()\n",
    "\n",
    "        for element in get_element(file_in, tags=('node', 'way')):\n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "#                if validate is True:\n",
    "#                    validate_element(el, validator)\n",
    "\n",
    "                if element.tag == 'node':\n",
    "                    nodes_writer.writerow(el['node'])\n",
    "                    node_tags_writer.writerows(el['node_tags'])\n",
    "                elif element.tag == 'way':\n",
    "                    ways_writer.writerow(el['way'])\n",
    "                    way_nodes_writer.writerows(el['way_nodes'])\n",
    "                    way_tags_writer.writerows(el['way_tags'])\n",
    "\n",
    "\n",
    "# Note: Validation is ~ 10X slower. For the project consider using a small\n",
    "# sample of the map when validating.\n",
    "process_map(OSMFILE, validate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              User   Count\n",
      "0          OklaNHD  332971\n",
      "1     dustybrimaps   97134\n",
      "2     Paul Johnson   59853\n",
      "3    JamesTheElder   51602\n",
      "4  William McBroom   32407\n",
      "5  woodpeck_fixbot   23368\n",
      "6          dufekin   22122\n",
      "7          JoeCat1   12240\n",
      "8            Rub21    8447\n",
      "9          mhenson    7538\n"
     ]
    }
   ],
   "source": [
    "# Create connection with the database and execute some SQL queries:\n",
    "# REFERENCE: 1) https://gist.github.com/carlward/54ec1c91b62a5f911c42#file-sample_project-md;\n",
    "# 2) https://stackoverflow.com/questions/7831371/is-there-a-way-to-get-a-list-of-column-names-in-sqlite\n",
    "\n",
    "connection = sqlite3.connect('EdmondDB.db')\n",
    "c = connection.cursor()\n",
    "\n",
    "#List top 10 contributors for the OSM data:\n",
    "\n",
    "QUERY = '''\n",
    "SELECT e.user as User, COUNT(*) as Count\n",
    "FROM (SELECT user FROM nodes UNION ALL SELECT user FROM ways) e\n",
    "GROUP BY e.user ORDER BY COUNT(*) DESC;\n",
    "'''\n",
    "\n",
    "cur = c.execute(QUERY)\n",
    "\n",
    "names = list(map(lambda x: x[0], cur.description))\n",
    "names = [description[0] for description in cur.description]\n",
    "\n",
    "rows = c.fetchall()\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df.columns = names\n",
    "print df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Amenity  Count\n",
      "0           parking    785\n",
      "1  place_of_worship    166\n",
      "2        restaurant    125\n",
      "3         fast_food    118\n",
      "4            school    109\n"
     ]
    }
   ],
   "source": [
    "QUERY = '''\n",
    "SELECT e.value as Amenity, COUNT(e.value) as Count\n",
    "FROM (SELECT key, value FROM nodes_tags WHERE nodes_tags.key='amenity'\n",
    "UNION ALL SELECT key, value FROM ways_tags\n",
    "WHERE ways_tags.key='amenity') e\n",
    "GROUP BY e.value ORDER BY COUNT(e.value) DESC;\n",
    "'''\n",
    "cur = c.execute(QUERY)\n",
    "\n",
    "names = list(map(lambda x: x[0], cur.description))\n",
    "names = [description[0] for description in cur.description]\n",
    "\n",
    "rows = c.fetchall()\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df.columns = names\n",
    "print df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Church  Count\n",
      "0                 baptist     29\n",
      "1                lutheran      8\n",
      "2               methodist      6\n",
      "3            presbyterian      5\n",
      "4                catholic      4\n",
      "5             pentecostal      4\n",
      "6        church_of_christ      3\n",
      "7                  mormon      3\n",
      "8          roman_catholic      3\n",
      "9             evangelical      2\n",
      "10  seventh_day_adventist      2\n",
      "11               anglican      1\n",
      "12         greek_orthodox      1\n",
      "13      nondenominational      1\n",
      "14               orthodox      1\n",
      "15             protestant      1\n",
      "16       southern_baptist      1\n",
      "17     ukrainian_orthodox      1\n"
     ]
    }
   ],
   "source": [
    "QUERY = '''\n",
    "SELECT e.value as Church, COUNT(e.value) as Count\n",
    "FROM (SELECT value FROM nodes_tags WHERE key='denomination'\n",
    "UNION ALL SELECT value FROM ways_tags WHERE ways_tags.key = 'denomination') e\n",
    "GROUP BY e.value ORDER BY COUNT(e.value) DESC, e.value;\n",
    "'''\n",
    "cur = c.execute(QUERY)\n",
    "\n",
    "names = list(map(lambda x: x[0], cur.description))\n",
    "names = [description[0] for description in cur.description]\n",
    "\n",
    "rows = c.fetchall()\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df.columns = names\n",
    "print df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Religion  Count\n",
      "0               christian    161\n",
      "1                  muslim      1\n",
      "2  unitarian_universalist      1\n"
     ]
    }
   ],
   "source": [
    "QUERY = '''\n",
    "SELECT e.value as Religion, COUNT(e.value) as Count\n",
    "FROM (SELECT value FROM nodes_tags WHERE key='religion'\n",
    "UNION ALL SELECT value FROM ways_tags WHERE ways_tags.key = 'religion') e\n",
    "GROUP BY e.value ORDER BY COUNT(e.value) DESC, e.value;\n",
    "'''\n",
    "cur = c.execute(QUERY)\n",
    "\n",
    "names = list(map(lambda x: x[0], cur.description))\n",
    "names = [description[0] for description in cur.description]\n",
    "\n",
    "rows = c.fetchall()\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df.columns = names\n",
    "print df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Cuisine  Count\n",
      "0     burger     46\n",
      "1    mexican     16\n",
      "2      pizza     15\n",
      "3   sandwich     14\n",
      "4    chicken     10\n",
      "5   american      8\n",
      "6    chinese      7\n",
      "7  ice_cream      7\n",
      "8    tex-mex      6\n",
      "9      asian      5\n"
     ]
    }
   ],
   "source": [
    "QUERY = '''\n",
    "SELECT e.value as Cuisine, COUNT(e.value) as Count\n",
    "FROM (SELECT value FROM nodes_tags WHERE key='cuisine'\n",
    "UNION ALL SELECT value FROM ways_tags WHERE ways_tags.key = 'cuisine') e\n",
    "GROUP BY e.value ORDER BY COUNT(e.value) DESC, e.value;\n",
    "'''\n",
    "cur = c.execute(QUERY)\n",
    "\n",
    "names = list(map(lambda x: x[0], cur.description))\n",
    "names = [description[0] for description in cur.description]\n",
    "\n",
    "rows = c.fetchall()\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df.columns = names\n",
    "print df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edmond elementary schools: 18\n",
      "Edmond middle schools: 6\n",
      "Edmond junior high/high schools: 14\n"
     ]
    }
   ],
   "source": [
    "QUERY1 = '''\n",
    "SELECT COUNT(DISTINCT(e.value)) as Elementary\n",
    "FROM (SELECT value FROM nodes_tags WHERE key='name' AND value LIKE '%Elementary School'\n",
    "UNION ALL SELECT value FROM ways_tags WHERE key = 'name' AND value LIKE '%Elementary School') e\n",
    "ORDER BY e.value;\n",
    "'''\n",
    "QUERY2 = '''\n",
    "SELECT COUNT(DISTINCT(e.value)) as Middle\n",
    "FROM (SELECT value FROM nodes_tags WHERE key='name' AND value LIKE '%Middle School'\n",
    "UNION ALL SELECT value FROM ways_tags WHERE key = 'name' AND value LIKE '%Middle School') e\n",
    "ORDER BY e.value;\n",
    "'''\n",
    "QUERY3 = '''\n",
    "SELECT COUNT(DISTINCT(e.value)) as High\n",
    "FROM (SELECT value FROM nodes_tags WHERE key='name' AND value LIKE '%High School'\n",
    "UNION ALL SELECT value FROM ways_tags WHERE key = 'name' AND value LIKE '%High School') e\n",
    "ORDER BY e.value;\n",
    "'''\n",
    "rows1 = c.execute(QUERY1).fetchall()\n",
    "rows2 = c.execute(QUERY2).fetchall()\n",
    "rows3 = c.execute(QUERY3).fetchall()\n",
    "print('Edmond elementary schools: ' + str(rows1[0][0]))\n",
    "print('Edmond middle schools: ' + str(rows2[0][0]))\n",
    "print('Edmond junior high/high schools: ' + str(rows3[0][0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Sport  Count\n",
      "0              tennis    112\n",
      "1            baseball     95\n",
      "2                golf     93\n",
      "3              soccer     59\n",
      "4          basketball     41\n",
      "5            swimming     31\n",
      "6   american_football     13\n",
      "7          volleyball      8\n",
      "8     beachvolleyball      5\n",
      "9               10pin      2\n",
      "10            fitness      2\n",
      "11           football      2\n",
      "12              motor      1\n",
      "13         skateboard      1\n",
      "14               yoga      1\n"
     ]
    }
   ],
   "source": [
    "QUERY = '''\n",
    "SELECT e.value as Sport, COUNT(e.value) as Count\n",
    "FROM (SELECT value FROM nodes_tags WHERE key='sport'\n",
    "UNION ALL SELECT value FROM ways_tags WHERE ways_tags.key = 'sport') e\n",
    "GROUP BY e.value ORDER BY COUNT(e.value) DESC, e.value;\n",
    "'''\n",
    "cur = c.execute(QUERY)\n",
    "\n",
    "names = list(map(lambda x: x[0], cur.description))\n",
    "names = [description[0] for description in cur.description]\n",
    "\n",
    "rows = c.fetchall()\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df.columns = names\n",
    "print df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Number                            Name        Type\n",
      "0       14                           Sonic   fast_food\n",
      "1       12                      McDonald's   fast_food\n",
      "2        7                         Braum's   fast_food\n",
      "3        5                     Chick-fil-A   fast_food\n",
      "4        5                       Taco Bell   fast_food\n",
      "5        5                     Whataburger   fast_food\n",
      "6        4                       Starbucks        cafe\n",
      "7        4                          Arby's   fast_food\n",
      "8        4                            IHOP  restaurant\n",
      "9        3                             KFC   fast_food\n",
      "10       3                   Panda Express   fast_food\n",
      "11       3                          Subway   fast_food\n",
      "12       2                     Burger King   fast_food\n",
      "13       2                      Carl's Jr.   fast_food\n",
      "14       2                        Chipotle   fast_food\n",
      "15       2                 Daylight Donuts   fast_food\n",
      "16       2                  Little Caesars   fast_food\n",
      "17       2                    Schlotzsky's   fast_food\n",
      "18       2               Schlotzsky's Deli   fast_food\n",
      "19       2                         Wendy's   fast_food\n",
      "20       2                         Chili's  restaurant\n",
      "21       2                     China House  restaurant\n",
      "22       2                      City Bites  restaurant\n",
      "23       2                   On The Border  restaurant\n",
      "24       2                   Papa Murphy's  restaurant\n",
      "25       2                       Pizza Hut  restaurant\n",
      "26       2                      The Garage  restaurant\n",
      "27       1            Aspen Coffee Company        cafe\n",
      "28       1                       Camilya's   fast_food\n",
      "29       1                        Del Taco   fast_food\n",
      "..     ...                             ...         ...\n",
      "58       1                    Golden Chick  restaurant\n",
      "59       1                 HD Onion Burger  restaurant\n",
      "60       1                  Hacienda Tacos  restaurant\n",
      "61       1                       Hidalgo's  restaurant\n",
      "62       1                       Hopscotch  restaurant\n",
      "63       1      Johnnie's Charcoal Broiler  restaurant\n",
      "64       1               Johnnie's Express  restaurant\n",
      "65       1             LongHorn Steakhouse  restaurant\n",
      "66       1                     Los Sabinos  restaurant\n",
      "67       1                        Mamaveca  restaurant\n",
      "68       1                         Mazzios  restaurant\n",
      "69       1                 New China House  restaurant\n",
      "70       1                          Nhinja  restaurant\n",
      "71       1                     Old Chicago  restaurant\n",
      "72       1                    Olive Garden  restaurant\n",
      "73       1                       Panang II  restaurant\n",
      "74       1                Piedmont Cuisine  restaurant\n",
      "75       1                Pizza Wheelhouse  restaurant\n",
      "76       1                           Pop's  restaurant\n",
      "77       1                     Red Lobster  restaurant\n",
      "78       1                          Rococo  restaurant\n",
      "79       1  Rudy's Country Store & Bar-B-Q  restaurant\n",
      "80       1            S & B's Burger Joint  restaurant\n",
      "81       1                       San Marco  restaurant\n",
      "82       1      Shogun Steakhouse of Japan  restaurant\n",
      "83       1           Stars & Stripes Pizza  restaurant\n",
      "84       1                    TGI Friday's  restaurant\n",
      "85       1                       Tana Thai  restaurant\n",
      "86       1                    Tao Cha Cafe  restaurant\n",
      "87       1                 Texas Roadhouse  restaurant\n",
      "\n",
      "[88 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "QUERY = '''\n",
    "SELECT COUNT(e.Name) as Number, e.Name, e.Type FROM\n",
    "(SELECT c.value as Type, b.value as Name, a.value as Cuisine \n",
    "FROM nodes_tags as a, nodes_tags as b, nodes_tags as c\n",
    "WHERE a.id = b.id AND a.id = c.id AND a.key = 'cuisine' AND a.type = 'regular' AND b.key = 'name' AND b.type = 'regular' AND c.key = 'amenity' AND c.type = 'regular'\n",
    "UNION ALL SELECT c.value as Type, b.value as Name, a.value as Cuisine \n",
    "FROM ways_tags as a, ways_tags as b, ways_tags as c\n",
    "WHERE a.id = b.id AND a.id = c.id AND a.key = 'cuisine' AND a.type = 'regular' AND b.key = 'name'  AND b.type = 'regular' AND c.key = 'amenity' AND c.type = 'regular') e\n",
    "GROUP BY e.Name ORDER BY Count(e.Name) DESC, e.Type, e.Name;\n",
    "'''\n",
    "cur = c.execute(QUERY)\n",
    "\n",
    "names = list(map(lambda x: x[0], cur.description))\n",
    "names = [description[0] for description in cur.description]\n",
    "\n",
    "rows = c.fetchall()\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df.columns = names\n",
    "print df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
